#  Performance Comparison of OpenAI GPT-3.5-turbo and Local LLM (Ollama Mistral) Using Streamlit.

  This project evaluates and compares the performance of two language models—OpenAI GPT-3.5-turbo and a local LLM (Ollama Mistral)—using a Streamlit application. The project aims to provide insights into the trade-offs between using a cloud-based solution versus a local model by measuring key metrics such as response time, CPU usage, and memory usage. The results help us understand how each model performs under different resource constraints and how efficiently they handle processing tasks, offering valuable guidance for choosing the most suitable model based on specific application requirements.

Comparison Parameters:
  -- Response Time
  -- CPU Usage
  -- Memory Usage


